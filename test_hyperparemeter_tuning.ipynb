{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "\n",
    "from src.options import Options\n",
    "from src.utils import setup\n",
    "from main import run as main\n",
    "from src.utils.hyperparemer_tuning_config import hyperparameter_config\n",
    "\n",
    "import ray\n",
    "from ray import tune, air\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.air import session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(hyperparameter_config: dict):\n",
    "    # Pretty print the run args\n",
    "    hyperparameter_config[\"data_dir\"] = '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data'\n",
    "    hyperparameter_config[\"data_class\"] = 'sind'\n",
    "    hyperparameter_config[\"pattern\"] = 'Ped_smoothed_tracks'\n",
    "    hyperparameter_config[\"data_class\"] = 'sind'\n",
    "    hyperparameter_config[\"pos_encoding\"] = 'learnable'\n",
    "    hyperparameter_config[\"name\"] = 'SINDDataset_pretrained'\n",
    "    hyperparameter_config[\"comment\"] = 'pretraining_through_imputation-hyperparameter_tuning'\n",
    "    hyperparameter_config[\"output_dir\"] = '/home/kfragkedaki/projects/Pedestrian_Project/ray_results'\n",
    "    hyperparameter_config[\"batch_size\"] = 512\n",
    "    hyperparameter_config[\"epochs\"] = 2\n",
    "\n",
    "    args_list = [f\"--{k}={v}\" for k, v in hyperparameter_config.items()]\n",
    "    args_list.append(\"--no_cuda\")\n",
    "    args_list.append(\"--hyperparameter_tuning\")\n",
    "    args_list.append(\"--harden\")\n",
    "    \n",
    "    opts = Options().parse(args_list) \n",
    "\n",
    "    pp.pprint(vars(opts))\n",
    "\n",
    "    main(setup(opts) , session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-13 22:27:01</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:00.58        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.9/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 14.0/14 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>status    </th><th>loc                  </th><th>activation  </th><th style=\"text-align: right;\">  data_chunk_len</th><th>data_normalization  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  harden_step</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  l2_reg</th><th style=\"text-align: right;\">         lr</th><th>mask_distribution  </th><th>mask_mode  </th><th>optimizer  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>run_ada61167</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>relu        </td><td style=\"text-align: right;\">             140</td><td>none                </td><td style=\"text-align: right;\">     0.15</td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">    0.15</td><td style=\"text-align: right;\">0.00018237 </td><td>geometric          </td><td>concurrent </td><td>Adam       </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        18.0125 </td><td style=\"text-align: right;\">117.847  </td></tr>\n",
       "<tr><td>run_0f15d889</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>relu        </td><td style=\"text-align: right;\">             140</td><td>none                </td><td style=\"text-align: right;\">     0.2 </td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">    0.2 </td><td style=\"text-align: right;\">8.04751e-05</td><td>geometric          </td><td>concurrent </td><td>Adam       </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        18.0949 </td><td style=\"text-align: right;\">121.684  </td></tr>\n",
       "<tr><td>run_6bd6d0c2</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>relu        </td><td style=\"text-align: right;\">             150</td><td>none                </td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">    0   </td><td style=\"text-align: right;\">0.000820223</td><td>geometric          </td><td>concurrent </td><td>Adam       </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.8126 </td><td style=\"text-align: right;\"> 74.2547 </td></tr>\n",
       "<tr><td>run_0cd89b64</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">              50</td><td>standardization     </td><td style=\"text-align: right;\">     0.15</td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.15</td><td style=\"text-align: right;\">2.73957e-05</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.5737 </td><td style=\"text-align: right;\">  1.19541</td></tr>\n",
       "<tr><td>run_3f321f7f</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>relu        </td><td style=\"text-align: right;\">             150</td><td>minmax              </td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">    0   </td><td style=\"text-align: right;\">0.000980439</td><td>geometric          </td><td>concurrent </td><td>Adam       </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        12.4393 </td><td style=\"text-align: right;\">  2.19525</td></tr>\n",
       "<tr><td>run_f9e5a437</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">              50</td><td>standardization     </td><td style=\"text-align: right;\">     0.1 </td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.1 </td><td style=\"text-align: right;\">0.000476107</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.51429</td><td style=\"text-align: right;\">  1.27003</td></tr>\n",
       "<tr><td>run_315848ca</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">              80</td><td>standardization     </td><td style=\"text-align: right;\">     0.2 </td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.2 </td><td style=\"text-align: right;\">0.000402612</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         9.31102</td><td style=\"text-align: right;\">  1.18379</td></tr>\n",
       "<tr><td>run_bcfa8055</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">              90</td><td>standardization     </td><td style=\"text-align: right;\">     0.1 </td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.1 </td><td style=\"text-align: right;\">2.07848e-05</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.3561 </td><td style=\"text-align: right;\">  1.52562</td></tr>\n",
       "<tr><td>run_f72f0c09</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">              80</td><td>standardization     </td><td style=\"text-align: right;\">     0.2 </td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.2 </td><td style=\"text-align: right;\">0.000475181</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         9.58252</td><td style=\"text-align: right;\">  1.12984</td></tr>\n",
       "<tr><td>run_a146ed08</td><td>TERMINATED</td><td>172.30.124.111:408936</td><td>gelu        </td><td style=\"text-align: right;\">             100</td><td>minmax              </td><td style=\"text-align: right;\">     0.05</td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.05</td><td style=\"text-align: right;\">0.000710672</td><td>bernoulli          </td><td>separate   </td><td>RAdam      </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.206  </td><td style=\"text-align: right;\">  1.23035</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'relu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 140,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'none',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.15000000000000002,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.15000000000000002,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0001823699391375394,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'geometric',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'concurrent',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'Adam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,453 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-02_BDQ'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,454 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,454 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,454 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,455 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,826 | INFO : 1021 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,826 | INFO : 256 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,852 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,853 | INFO : Total number of parameters: 614406\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:02,853 | INFO : Trainable parameters: 614406\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,243 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,244 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 1616.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,853 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.6085033416748047 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,853 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.6085033416748047 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,853 | INFO : Avg batch val. time: 0.6085033416748047 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,853 | INFO : Avg sample val. time: 0.002376966178417206 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:03,853 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 1616.974710 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         2\t|\tloss: 128.481\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         1 of         2\t|\tloss: 126.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:11,825 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 127.529835 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:11,825 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 7.964800119400024 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:11,825 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 7.964800119400024 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:11,825 | INFO : Avg batch train. time: 3.982400059700012 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:11,825 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 117.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,364 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5387990474700928 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,364 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5736511945724487 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,364 | INFO : Avg batch val. time: 0.5736511945724487 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,364 | INFO : Avg sample val. time: 0.002240824978798628 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,364 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 117.859378 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:12,429 | INFO : Learning rate updated to: 0.0001823699391375394\n",
      "Training Epoch:  50%|█████     | 1/2 [00:08<00:08,  8.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         2\t|\tloss: 122.954\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         1 of         2\t|\tloss: 120.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:19,888 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 121.488291 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:19,888 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 7.4582133293151855 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:19,888 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 7.711506724357605 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:19,889 | INFO : Avg batch train. time: 3.8557533621788025 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:19,889 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 117.847\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'relu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 140,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'none',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 8.047511591463655e-05,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'geometric',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'concurrent',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'Adam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,467 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5778458118438721 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,467 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5750494003295898 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,467 | INFO : Avg batch val. time: 0.5750494003295898 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,467 | INFO : Avg sample val. time: 0.0022462867200374603 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,467 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 117.847233 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,515 | INFO : Learning rate updated to: 0.0001823699391375394\n",
      "2024-03-13 22:25:20,515 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-02_BDQ', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'none', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 140, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'concurrent', 'mask_distribution': 'geometric', 'exclude_feats': None, 'harden': True, 'harden_step': 15, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.0001823699391375394, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'Adam', 'l2_reg': 0.15000000000000002, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 512, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.15000000000000002, 'pos_encoding': 'learnable', 'activation': 'relu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-25-02', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-02_BDQ/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-02_BDQ/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,529 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,531 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,531 | INFO : Best loss was 117.84723300552105. Other metrics: OrderedDict([('epoch', 2), ('loss', 117.84723300552105)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,531 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,531 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 18.07836365699768 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,558 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-20_3FL'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,559 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,559 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,559 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:20,560 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,027 | INFO : 1021 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,027 | INFO : 256 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,052 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,052 | INFO : Total number of parameters: 614406\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,053 | INFO : Trainable parameters: 614406\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,053 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,055 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 1557.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,694 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.6391491889953613 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,694 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5910743474960327 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,694 | INFO : Avg batch val. time: 0.5910743474960327 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,694 | INFO : Avg sample val. time: 0.002308884169906378 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:21,694 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 1557.094588 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         2\t|\tloss: 125.342\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         1 of         2\t|\tloss: 128.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:29,680 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 126.798397 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:29,680 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 7.9762420654296875 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:29,681 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 7.9762420654296875 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:29,681 | INFO : Avg batch train. time: 3.9881210327148438 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:29,681 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 121.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,223 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5422024726867676 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,224 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5812999725341796 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,224 | INFO : Avg batch val. time: 0.5812999725341796 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,224 | INFO : Avg sample val. time: 0.0022707030177116392 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,224 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 121.847381 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:30,266 | INFO : Learning rate updated to: 8.047511591463655e-05\n",
      "Training Epoch:  50%|█████     | 1/2 [00:08<00:08,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         2\t|\tloss: 124.401\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         1 of         2\t|\tloss: 128.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,133 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 126.452368 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,133 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 7.866470813751221 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,133 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 7.921356439590454 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,133 | INFO : Avg batch train. time: 3.960678219795227 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,133 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 121.684\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'relu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 150,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'none',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 20,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0008202234595501656,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'geometric',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'concurrent',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'Adam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,644 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5113415718078613 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,645 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5696402390797933 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,645 | INFO : Avg batch val. time: 0.5696402390797933 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,645 | INFO : Avg sample val. time: 0.0022251571839054427 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,645 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 121.684213 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,686 | INFO : Learning rate updated to: 8.047511591463655e-05\n",
      "2024-03-13 22:25:38,687 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-20_3FL', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'none', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 140, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'concurrent', 'mask_distribution': 'geometric', 'exclude_feats': None, 'harden': True, 'harden_step': 15, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 8.047511591463655e-05, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'Adam', 'l2_reg': 0.2, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 512, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.2, 'pos_encoding': 'learnable', 'activation': 'relu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-25-20', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-20_3FL/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-20_3FL/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,697 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,699 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,699 | INFO : Best loss was 121.68421313949793. Other metrics: OrderedDict([('epoch', 2), ('loss', 121.68421313949793)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,699 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,699 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 18.141722440719604 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,723 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-38_lHh'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,724 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,724 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,724 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:38,725 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,299 | INFO : 998 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,299 | INFO : 250 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,326 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,326 | INFO : Total number of parameters: 615686\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,326 | INFO : Trainable parameters: 615686\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,328 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:39,329 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 4294.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:40,044 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.7143487930297852 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:40,044 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5903128896440778 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:40,044 | INFO : Avg batch val. time: 0.5903128896440778 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:40,044 | INFO : Avg sample val. time: 0.002361251558576311 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:40,044 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 4294.133816 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         2\t|\tloss: 127.759\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         1 of         2\t|\tloss: 119.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,079 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 123.825869 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,080 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 6.025205373764038 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,080 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 6.025205373764038 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,080 | INFO : Avg batch train. time: 3.012602686882019 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,080 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 98.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,664 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5834650993347168 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,664 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5894569158554077 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,664 | INFO : Avg batch val. time: 0.5894569158554077 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,664 | INFO : Avg sample val. time: 0.002357827663421631 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,664 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 98.524600 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:46,716 | INFO : Learning rate updated to: 0.0008202234595501656\n",
      "Training Epoch:  50%|█████     | 1/2 [00:06<00:06,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         2\t|\tloss: 118.705\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         1 of         2\t|\tloss: 108.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:52,997 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 113.718732 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:52,998 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 6.280341625213623 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:52,998 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 6.152773499488831 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:52,998 | INFO : Avg batch train. time: 3.0763867497444153 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:52,998 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 74.2547\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 50,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'standardization',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.15000000000000002,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.15000000000000002,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 2.73956990532914e-05,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,534 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.5366966724395752 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,535 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5835946665869819 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,535 | INFO : Avg batch val. time: 0.5835946665869819 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,535 | INFO : Avg sample val. time: 0.0023343786663479276 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,535 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 74.254658 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,569 | INFO : Learning rate updated to: 0.0008202234595501656\n",
      "2024-03-13 22:25:53,569 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-38_lHh', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'none', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 150, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'concurrent', 'mask_distribution': 'geometric', 'exclude_feats': None, 'harden': True, 'harden_step': 20, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.0008202234595501656, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'Adam', 'l2_reg': 0.0, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 512, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.0, 'pos_encoding': 'learnable', 'activation': 'relu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-25-38', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-38_lHh/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-38_lHh/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,580 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,581 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,581 | INFO : Best loss was 74.2546584179357. Other metrics: OrderedDict([('epoch', 2), ('loss', 74.2546584179357)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,582 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,582 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 14.858084917068481 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,608 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-53_LaZ'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,609 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,609 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,609 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:53,610 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,099 | INFO : 2037 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,099 | INFO : 510 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,120 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,131 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.15000000000000002, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,131 | INFO : Total number of parameters: 405510\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,131 | INFO : Trainable parameters: 405510\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,132 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,134 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 24.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,455 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.3215148448944092 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,455 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5573866844177247 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,455 | INFO : Avg batch val. time: 0.5573866844177247 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,455 | INFO : Avg sample val. time: 0.0010929150674857345 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:54,456 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 24.084830 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         4\t|\tloss: 1.20949\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  25.0% | batch:         1 of         4\t|\tloss: 1.20309\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         2 of         4\t|\tloss: 1.19957\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  75.0% | batch:         3 of         4\t|\tloss: 1.20221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,666 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.203639 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,666 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.2039380073547363 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,666 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.2039380073547363 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,666 | INFO : Avg batch train. time: 0.8009845018386841 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,666 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 1.55958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,904 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.2376420497894287 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,904 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5283189903606068 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,904 | INFO : Avg batch val. time: 0.5283189903606068 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,904 | INFO : Avg sample val. time: 0.0010359195889423664 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,904 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 1.559584 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:25:57,943 | INFO : Learning rate updated to: 2.73956990532914e-05\n",
      "Training Epoch:  50%|█████     | 1/2 [00:03<00:03,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         4\t|\tloss: 1.16074\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  25.0% | batch:         1 of         4\t|\tloss: 1.2901\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         2 of         4\t|\tloss: 1.17717\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  75.0% | batch:         3 of         4\t|\tloss: 1.26362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:00,890 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 1.222618 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:00,890 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 2.946643352508545 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:00,890 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.0752906799316406 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:00,890 | INFO : Avg batch train. time: 0.7688226699829102 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:00,890 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.19541\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'relu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 150,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'minmax',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 20,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0009804390713350226,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'geometric',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'concurrent',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'Adam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,176 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.2858130931854248 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,176 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5081101655960083 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,176 | INFO : Avg batch val. time: 0.5081101655960083 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,176 | INFO : Avg sample val. time: 0.0009962944423451143 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,177 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.195412 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,219 | INFO : Learning rate updated to: 2.73956990532914e-05\n",
      "2024-03-13 22:26:01,219 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-53_LaZ', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'standardization', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 50, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'separate', 'mask_distribution': 'bernoulli', 'exclude_feats': None, 'harden': True, 'harden_step': 15, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 2.73956990532914e-05, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'RAdam', 'l2_reg': 0.15000000000000002, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 256, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.15000000000000002, 'pos_encoding': 'learnable', 'activation': 'gelu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-25-53', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-53_LaZ/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-25-53_LaZ/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,228 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,230 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,230 | INFO : Best loss was 1.1954121284711092. Other metrics: OrderedDict([('epoch', 2), ('loss', 1.1954121284711092)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,231 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,231 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 7.62262487411499 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,254 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-01_avH'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,255 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,256 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,256 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,257 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,779 | INFO : 998 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,779 | INFO : 250 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,798 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,808 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.0, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,809 | INFO : Total number of parameters: 615686\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,809 | INFO : Trainable parameters: 615686\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,810 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:01,811 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 6.39978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:02,264 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4527015686035156 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:02,264 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.503847965827355 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:02,264 | INFO : Avg batch val. time: 0.503847965827355 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:02,264 | INFO : Avg sample val. time: 0.00201539186330942 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:02,264 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 6.399784 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         2\t|\tloss: 0.352032\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         1 of         2\t|\tloss: 0.0342072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,279 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 0.203464 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,279 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 5.008637189865112 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,279 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 5.008637189865112 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,279 | INFO : Avg batch train. time: 2.504318594932556 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,279 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 4.53865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,764 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.48519420623779297 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,765 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5025155544281006 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,765 | INFO : Avg batch val. time: 0.5025155544281006 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,765 | INFO : Avg sample val. time: 0.0020100622177124023 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,765 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 4.538651 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:07,823 | INFO : Learning rate updated to: 0.0009804390713350226\n",
      "Training Epoch:  50%|█████     | 1/2 [00:05<00:05,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         2\t|\tloss: 0.0333401\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         1 of         2\t|\tloss: 0.0218346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,223 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 0.027645 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,223 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 5.399377346038818 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,223 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 5.204007267951965 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,223 | INFO : Avg batch train. time: 2.6020036339759827 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,223 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 2.19525\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 50,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'standardization',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 10,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0004761066646858594,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,690 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.46683645248413086 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,690 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5001369476318359 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,690 | INFO : Avg batch val. time: 0.5001369476318359 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,690 | INFO : Avg sample val. time: 0.0020005477905273438 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,691 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 2.195255 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,738 | INFO : Learning rate updated to: 0.0009804390713350226\n",
      "2024-03-13 22:26:13,739 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-01_avH', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'minmax', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 150, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'concurrent', 'mask_distribution': 'geometric', 'exclude_feats': None, 'harden': True, 'harden_step': 20, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.0009804390713350226, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'Adam', 'l2_reg': 0.0, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 512, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.0, 'pos_encoding': 'learnable', 'activation': 'relu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-26-01', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-01_avH/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-01_avH/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,746 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,747 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,747 | INFO : Best loss was 2.1952549567488866. Other metrics: OrderedDict([('epoch', 2), ('loss', 2.1952549567488866)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,747 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,747 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 12.49261999130249 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,770 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-13_eZs'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,770 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,770 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,770 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:13,771 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,300 | INFO : 2037 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,301 | INFO : 510 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,322 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,332 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,333 | INFO : Total number of parameters: 405510\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,333 | INFO : Trainable parameters: 405510\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,334 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,335 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 24.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,631 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.2954225540161133 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,631 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48734229803085327 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,631 | INFO : Avg batch val. time: 0.48734229803085327 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,631 | INFO : Avg sample val. time: 0.00095557313339383 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:14,631 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 24.274448 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         4\t|\tloss: 1.17677\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  25.0% | batch:         1 of         4\t|\tloss: 1.19987\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  50.0% | batch:         2 of         4\t|\tloss: 1.20089\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  75.0% | batch:         3 of         4\t|\tloss: 1.20848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,713 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.196256 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,714 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.0752129554748535 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,714 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.0752129554748535 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,714 | INFO : Avg batch train. time: 0.7688032388687134 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,714 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 1.62071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,958 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.24371838569641113 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,958 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47301147965823903 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,958 | INFO : Avg batch val. time: 0.47301147965823903 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,958 | INFO : Avg sample val. time: 0.0009274734895259589 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,958 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 1.620711 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:17,996 | INFO : Learning rate updated to: 0.0004761066646858594\n",
      "Training Epoch:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         4\t|\tloss: 1.23207\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  25.0% | batch:         1 of         4\t|\tloss: 1.27306\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  50.0% | batch:         2 of         4\t|\tloss: 1.15931\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  75.0% | batch:         3 of         4\t|\tloss: 1.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,026 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 1.219804 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,026 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.029400587081909 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,026 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.0523067712783813 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,027 | INFO : Avg batch train. time: 0.7630766928195953 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,027 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.27003\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 80,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'standardization',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0004026121896784705,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,276 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.24983429908752441 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,277 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.46061274740431046 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,277 | INFO : Avg batch val. time: 0.46061274740431046 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,277 | INFO : Avg sample val. time: 0.0009031622498123735 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,277 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.270032 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,307 | INFO : Learning rate updated to: 0.0004761066646858594\n",
      "2024-03-13 22:26:21,307 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-13_eZs', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'standardization', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 50, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'separate', 'mask_distribution': 'bernoulli', 'exclude_feats': None, 'harden': True, 'harden_step': 10, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.0004761066646858594, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'RAdam', 'l2_reg': 0.1, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 256, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.1, 'pos_encoding': 'learnable', 'activation': 'gelu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-26-13', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-13_eZs/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-13_eZs/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,317 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,318 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,318 | INFO : Best loss was 1.2700317644953472. Other metrics: OrderedDict([('epoch', 2), ('loss', 1.2700317644953472)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,318 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,318 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 7.548651218414307 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,347 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-21_EKI'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,348 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,349 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,349 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,350 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,936 | INFO : 1434 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,936 | INFO : 359 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,957 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,970 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,970 | INFO : Total number of parameters: 409350\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,970 | INFO : Trainable parameters: 409350\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,971 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:21,973 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 19.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:22,346 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.3727993965148926 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:22,346 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4559909920943411 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:22,346 | INFO : Avg batch val. time: 0.4559909920943411 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:22,346 | INFO : Avg sample val. time: 0.0012701698944132063 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:22,346 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 19.149471 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         3\t|\tloss: 1.02449\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  33.3% | batch:         1 of         3\t|\tloss: 1.06399\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  66.7% | batch:         2 of         3\t|\tloss: 1.19622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,219 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.089698 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,219 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.867841958999634 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,219 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.867841958999634 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,219 | INFO : Avg batch train. time: 1.289280652999878 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,220 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 1.46945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,491 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.2711937427520752 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,491 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4467511296272278 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,491 | INFO : Avg batch val. time: 0.4467511296272278 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,491 | INFO : Avg sample val. time: 0.0012444321159532808 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,491 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 1.469445 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:26,532 | INFO : Learning rate updated to: 0.0004026121896784705\n",
      "Training Epoch:  50%|█████     | 1/2 [00:04<00:04,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         3\t|\tloss: 1.08662\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  33.3% | batch:         1 of         3\t|\tloss: 1.16134\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  66.7% | batch:         2 of         3\t|\tloss: 1.01584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,418 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 1.094224 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,418 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.8849833011627197 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,418 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.8764126300811768 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,419 | INFO : Avg batch train. time: 1.2921375433603923 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,419 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.18379\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 90,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'standardization',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 10,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 2.0784760655051732e-05,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,656 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.23739194869995117 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,656 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.436781644821167 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,656 | INFO : Avg batch val. time: 0.436781644821167 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,656 | INFO : Avg sample val. time: 0.0012166619632901588 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,657 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.183785 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,701 | INFO : Learning rate updated to: 0.0004026121896784705\n",
      "2024-03-13 22:26:30,702 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-21_EKI', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'standardization', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 80, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'separate', 'mask_distribution': 'bernoulli', 'exclude_feats': None, 'harden': True, 'harden_step': 15, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.0004026121896784705, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'RAdam', 'l2_reg': 0.2, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 256, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.2, 'pos_encoding': 'learnable', 'activation': 'gelu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-26-21', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-21_EKI/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-21_EKI/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,711 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,713 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,713 | INFO : Best loss was 1.1837853713398274. Other metrics: OrderedDict([('epoch', 2), ('loss', 1.1837853713398274)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,713 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,713 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 9.365718841552734 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,737 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-30_V7B'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,738 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,738 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,738 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:30,740 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,400 | INFO : 1316 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,400 | INFO : 329 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,420 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,430 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,431 | INFO : Total number of parameters: 410630\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,431 | INFO : Trainable parameters: 410630\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,432 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,433 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 26.2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,844 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4104037284851074 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,844 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.43558264862407337 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,844 | INFO : Avg batch val. time: 0.43558264862407337 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,844 | INFO : Avg sample val. time: 0.0013239594183102534 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:31,844 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 26.293903 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         3\t|\tloss: 1.04088\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  33.3% | batch:         1 of         3\t|\tloss: 1.13721\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  66.7% | batch:         2 of         3\t|\tloss: 1.19196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,137 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.110430 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,137 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 4.285299301147461 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,137 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 4.285299301147461 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,137 | INFO : Avg batch train. time: 1.428433100382487 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,137 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 2.09582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,462 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.3240647315979004 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,462 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4307340435359789 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,462 | INFO : Avg batch val. time: 0.4307340435359789 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,462 | INFO : Avg sample val. time: 0.0013092220168266836 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,462 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 2.095824 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:36,516 | INFO : Learning rate updated to: 2.0784760655051732e-05\n",
      "Training Epoch:  50%|█████     | 1/2 [00:04<00:04,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         3\t|\tloss: 1.06748\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  33.3% | batch:         1 of         3\t|\tloss: 1.06493\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  66.7% | batch:         2 of         3\t|\tloss: 1.21039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:40,740 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 1.098710 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:40,740 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 4.222586393356323 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:40,740 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 4.253942847251892 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:40,740 | INFO : Avg batch train. time: 1.417980949083964 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:40,740 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.52562\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 80,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'standardization',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.00047518136051345565,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,096 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.355912446975708 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,096 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4276164770126343 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,096 | INFO : Avg batch val. time: 0.4276164770126343 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,096 | INFO : Avg sample val. time: 0.0012997461307374901 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,097 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.525623 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,132 | INFO : Learning rate updated to: 2.0784760655051732e-05\n",
      "2024-03-13 22:26:41,132 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-30_V7B', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'standardization', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 90, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'separate', 'mask_distribution': 'bernoulli', 'exclude_feats': None, 'harden': True, 'harden_step': 10, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 2.0784760655051732e-05, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'RAdam', 'l2_reg': 0.1, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 256, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.1, 'pos_encoding': 'learnable', 'activation': 'gelu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-26-30', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-30_V7B/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-30_V7B/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,139 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,139 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,139 | INFO : Best loss was 1.5256225159083516. Other metrics: OrderedDict([('epoch', 2), ('loss', 1.5256225159083516)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,140 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,140 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 10.40238904953003 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,160 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-41_Qpl'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,161 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,161 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,161 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,162 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,725 | INFO : 1434 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,725 | INFO : 359 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,748 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,763 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.2, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,763 | INFO : Total number of parameters: 409350\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,764 | INFO : Trainable parameters: 409350\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,764 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:41,766 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 18.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:42,150 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.384080171585083 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:42,150 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.42587502479553224 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:42,150 | INFO : Avg batch val. time: 0.42587502479553224 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:42,150 | INFO : Avg sample val. time: 0.0011862814061156888 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:42,151 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 18.919767 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         3\t|\tloss: 1.04553\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  33.3% | batch:         1 of         3\t|\tloss: 1.05862\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  66.7% | batch:         2 of         3\t|\tloss: 1.16345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,237 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.085156 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,237 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 4.081482648849487 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,237 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 4.081482648849487 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,237 | INFO : Avg batch train. time: 1.3604942162831624 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,237 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 1.47931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,520 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.28278541564941406 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,520 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4203715782899123 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,521 | INFO : Avg batch val. time: 0.4203715782899123 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,521 | INFO : Avg sample val. time: 0.0011709514715596444 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,521 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 1.479312 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:46,556 | INFO : Learning rate updated to: 0.00047518136051345565\n",
      "Training Epoch:  50%|█████     | 1/2 [00:04<00:04,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         3\t|\tloss: 1.10451\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  33.3% | batch:         1 of         3\t|\tloss: 1.08915\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  66.7% | batch:         2 of         3\t|\tloss: 1.05871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,467 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 1.086135 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,467 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 3.911017894744873 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,467 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 3.99625027179718 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,467 | INFO : Avg batch train. time: 1.3320834239323933 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,467 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.12984\n",
      "\u001b[36m(run pid=408936)\u001b[0m {'activation': 'gelu',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'batch_size': 512,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'comment': 'pretraining_through_imputation-hyperparameter_tuning',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'config_filepath': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'console': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_chunk_len': 100,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_class': 'sind',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'data_normalization': 'minmax',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'dropout': 0.05,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_delta': 0.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'early_stopping_patience': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'epochs': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'eval_only': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'exclude_feats': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'experiment_name': 'SINDDataset_pretrained',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'harden_step': 15,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hidden_dim': 256,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'l2_reg': 0.05,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'load_model': None,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr': 0.0007106716060801806,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'lr_step': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_distribution': 'bernoulli',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mask_mode': 'separate',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'masking_ratio': 0.1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'max_grad_norm': 4.0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'mean_mask_length': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'n_proc': -1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'no_cuda': True,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'normalization_layer': 'BatchNorm',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_heads': 8,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_layers': 3,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'num_workers': 0,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'optimizer': 'RAdam',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pattern': 'Ped_smoothed_tracks',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'pos_encoding': 'learnable',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'print_interval': 1,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'records_file': './records.xls',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'resume': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_all': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'save_embeddings': False,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'seed': 1337,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'task': 'imputation',\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_interval': 2,\n",
      "\u001b[36m(run pid=408936)\u001b[0m  'val_ratio': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,741 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.27336645126342773 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,741 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.41492694395559804 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,741 | INFO : Avg batch val. time: 0.41492694395559804 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,741 | INFO : Avg sample val. time: 0.001155785359207794 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,741 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.129838 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,784 | INFO : Learning rate updated to: 0.00047518136051345565\n",
      "2024-03-13 22:26:50,784 | INFO : {'config_filepath': None, 'output_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-41_Qpl', 'data_dir': '/home/kfragkedaki/projects/Pedestrian_Project/resources/SinD/Data', 'load_model': None, 'resume': False, 'save_all': False, 'experiment_name': 'SINDDataset_pretrained', 'comment': 'pretraining_through_imputation-hyperparameter_tuning', 'records_file': './records.xls', 'console': False, 'print_interval': 1, 'no_cuda': True, 'n_proc': -1, 'num_workers': 0, 'seed': 1337, 'data_class': 'sind', 'data_normalization': 'standardization', 'pattern': 'Ped_smoothed_tracks', 'val_ratio': 0.2, 'data_chunk_len': 80, 'task': 'imputation', 'masking_ratio': 0.1, 'mean_mask_length': 3, 'mask_mode': 'separate', 'mask_distribution': 'bernoulli', 'exclude_feats': None, 'harden': True, 'harden_step': 15, 'early_stopping_patience': None, 'early_stopping_delta': 0.0, 'epochs': 2, 'val_interval': 2, 'batch_size': 512, 'lr': 0.00047518136051345565, 'lr_step': 1, 'lr_decay': 1.0, 'optimizer': 'RAdam', 'l2_reg': 0.2, 'max_grad_norm': 4.0, 'eval_only': False, 'save_embeddings': False, 'embedding_dim': 128, 'hidden_dim': 256, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.2, 'pos_encoding': 'learnable', 'activation': 'gelu', 'normalization_layer': 'BatchNorm', 'hyperparameter_tuning': True, 'initial_timestamp': '2024-03-13_22-26-41', 'save_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-41_Qpl/checkpoints', 'tensorboard_dir': '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-41_Qpl/tb_summaries'}\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,793 | WARNING : Records file './records.xls' does not exist! Creating new file ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,794 | INFO : Exported performance record to './records.xls'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,795 | INFO : Best loss was 1.1298382816755506. Other metrics: OrderedDict([('epoch', 2), ('loss', 1.1298382816755506)])\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,795 | INFO : All Done!\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,795 | INFO : Total runtime: 0.0 hours, 0.0 minutes, 9.634852409362793 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,814 | INFO : Stored configuration file in '/home/kfragkedaki/projects/Pedestrian_Project/ray_results/SINDDataset_pretrained_2024-03-13_22-26-50_kMI'\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,814 | INFO : Running:\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=172.30.124.111 --node-manager-port=42715 --object-store-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/plasma_store --raylet-name=/tmp/ray/session_2024-03-13_22-24-57_355499_407966/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=65293 --runtime-env-agent-port=50319 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=50319 --gcs-address=172.30.124.111:63144 --session-name=session_2024-03-13_22-24-57_355499_407966 --temp-dir=/tmp/ray --webui= --cluster-id=1a424adfba121161a6e6cb85bf7fae0f41acae91f969e4e8a326f2df --startup-token=14 --worker-launch-time-ms=1710365100621 --runtime-env-hash=-1413791333\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,815 | INFO : Using device: cpu\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,815 | INFO : Loading and preprocessing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:50,816 | INFO : Loading 24 datasets files using 20 parallel processes ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m max_seq_len 350\n",
      "\u001b[36m(run pid=408936)\u001b[0m final max_seq_len 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,362 | INFO : 1237 samples may be used for training\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,362 | INFO : 310 samples will be used for validation\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,382 | INFO : Normalizing data ...\n",
      "\u001b[36m(run pid=408936)\u001b[0m /home/kfragkedaki/miniconda3/envs/pedestrian_project/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\u001b[36m(run pid=408936)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,392 | INFO : Model:\n",
      "\u001b[36m(run pid=408936)\u001b[0m TSTransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (project_inp): Linear(in_features=6, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (pos_enc): LearnablePositionalEncoding(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (dropout): Dropout(p=0.05, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (transformer_encoder): TransformerEncoder(\n",
      "\u001b[36m(run pid=408936)\u001b[0m     (layers): ModuleList(\n",
      "\u001b[36m(run pid=408936)\u001b[0m       (0-2): 3 x TransformerBatchNormEncoderLayer(\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (self_attn): MultiheadAttention(\n",
      "\u001b[36m(run pid=408936)\u001b[0m           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         )\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout): Dropout(p=0.05, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout1): Dropout(p=0.05, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m         (dropout2): Dropout(p=0.05, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m       )\n",
      "\u001b[36m(run pid=408936)\u001b[0m     )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   )\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (dropout1): Dropout(p=0.05, inplace=False)\n",
      "\u001b[36m(run pid=408936)\u001b[0m   (output_layer): Linear(in_features=128, out_features=6, bias=True)\n",
      "\u001b[36m(run pid=408936)\u001b[0m )\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,392 | INFO : Total number of parameters: 411910\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,392 | INFO : Trainable parameters: 411910\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,393 | INFO : Starting training...\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,394 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 0   0.0% | batch:         0 of         1\t|\tloss: 12.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,725 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.33091282844543457 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,726 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4119264398302351 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,726 | INFO : Avg batch val. time: 0.4119264398302351 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,726 | INFO : Avg sample val. time: 0.0013287949671943067 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:51,726 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 12.192618 | \n",
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1   0.0% | batch:         0 of         3\t|\tloss: 0.296369\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  33.3% | batch:         1 of         3\t|\tloss: 0.292717\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 1  66.7% | batch:         2 of         3\t|\tloss: 0.288434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,026 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 0.293502 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,026 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 4.286871910095215 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,026 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 4.286871910095215 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,026 | INFO : Avg batch train. time: 1.4289573033650715 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,026 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 1   0.0% | batch:         0 of         1\t|\tloss: 3.11616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,394 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.36751699447631836 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,394 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4103950796456173 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,394 | INFO : Avg batch val. time: 0.4103950796456173 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,394 | INFO : Avg sample val. time: 0.0013238550956310236 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,394 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 3.116155 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:26:56,431 | INFO : Learning rate updated to: 0.0007106716060801806\n",
      "Training Epoch:  50%|█████     | 1/2 [00:04<00:04,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2   0.0% | batch:         0 of         3\t|\tloss: 0.284646\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  33.3% | batch:         1 of         3\t|\tloss: 0.284673\n",
      "\u001b[36m(run pid=408936)\u001b[0m Training Epoch 2  66.7% | batch:         2 of         3\t|\tloss: 0.294399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:00,724 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 0.286305 | \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:00,724 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 4.292231321334839 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:00,725 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 4.289551615715027 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:00,725 | INFO : Avg batch train. time: 1.4298505385716755 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:00,725 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m Evaluating Epoch 2   0.0% | batch:         0 of         1\t|\tloss: 1.23035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:01,015 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.29048728942871094 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m \n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:01,015 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4063981533050537 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:01,015 | INFO : Avg batch val. time: 0.4063981533050537 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:01,015 | INFO : Avg sample val. time: 0.001310961784855012 seconds\n",
      "\u001b[36m(run pid=408936)\u001b[0m 2024-03-13 22:27:01,016 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 1.230351 | \n",
      "2024-03-13 22:27:01,082\tINFO tune.py:1042 -- Total run time: 120.60 seconds (120.57 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 10\n",
    "ray.init(num_cpus=14)\n",
    "searcher = HyperOptSearch(\n",
    "    space=hyperparameter_config, metric=\"loss\", mode=\"min\", n_initial_points=int(N_ITER / 10)\n",
    ")\n",
    "algo = ConcurrencyLimiter(searcher, max_concurrent=3)\n",
    "objective = tune.with_resources(\n",
    "    tune.with_parameters(run), resources={\"cpu\": 14}\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable=objective,\n",
    "    run_config=air.RunConfig(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        search_alg=algo,\n",
    "        num_samples=N_ITER,\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_thesis_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
